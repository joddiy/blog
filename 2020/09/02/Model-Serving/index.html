
<!DOCTYPE html>
<html lang="en">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Jz Blog">
    <title>Model Serving - Jz Blog</title>
    <meta name="author" content="Joddiy Zhang">
    
    
        <link rel="icon" href="http://joddiy.cc/assets/images/favicon.ico">
    
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Joddiy Zhang","sameAs":["https://github.com/joddiy","https://scholar.google.com/citations?user=KH-xv38AAAAJ&hl=en&oi=sra","https://www.linkedin.com/in/joddiyzhang/"],"image":"14108933.jpeg"},"articleBody":"From the Edge to the Cloud: Model Serving in ML.NETIn this paper, they:\n\ngive an overview of current state of the art practices for surfacing ML pipelines predictions into applications\nhighlight the limitations of using containers to operationalize models for application consumption.\n\nModel Serving: An Overview\nDeploying Models into ContainersThe first option, depicted in Figure 2(a) is to ship models into containers (e.g., Docker [4]) wired with proper Remote Procedure Calls(RPCs) to a Web Server. With this approach, predictions have to go through the network and be rendered on the cloud: low latency or edge scenarios are therefore out of scope.\nPros:\n\ndecoupling models from serving system development.\neases the implementation of mechanisms and policies for fault tolerance and scalability. \nhardware acceleration can be exploited when available.\n\nCons:\n\neach container comes with its own runtime and set of processes, thus introducing memory overheads that can possibly be higher than the actual model size.\nthe RPC layer and REST API introduce network communication costs.\nonly a restricted set of optimizations are available, no knowledge of the internals of the pipelines.\n\nImporting Models Directly into ApplicationsThe second option (Figure 2(b) is to integrate the model logic directly into the application(ML.NET: the model is a dynamic library the application can link). This approach is suitable for the cloud as well as for edge devices and it unlocks low latency scenarios.\nPros:\n\nremoves the overhead of managing containers and implementing RPC functionalities to communicate with the Serving System.\n\nCons:\n\nsub-optimal from a performance perspective, DAGs with high chance of overlapping structure and similar parameters, but these similarities cannot be recognized nor exploited using a black-box approach.\n\nWhite Box Model ServingModels are registered to a Runtime that considers them not as mere executable code but as DAGs of operators.\nPros:\n\napply optimizations over the models such as operator reordering to improve latency or operator and sub-graph sharing to improve memory consumption and computation reuse.\n\nEnd-to-end Optimizations:\n\navoid memory allocation on the data path\navoid creating separate routines per operator when possible\navoid reflection and JIT compilation at prediction time\n\nMulti-model Optimizations:\n\nshareable components have to be uniquely stored in memory and reused as much as possible to achieve optimal memory usage\n\nPRETZELPRETZEL views models as database queries and employs database techniques to optimize DAGs and to improve end-to-end performance.\n\noff-line phase:\n\npre-trained ML.NET pipelines are translated into Flour transformations. \nOven optimizer re-arranges and fuses transformations into model plans composed of parameterized logical units called stages. \nEach logical stage is then Ahead-Of-Time(AOT)-compiled into physical computation units. \nLogical and physical stages together with model parameters and training statistics form a model plan. \nModel plans are registered for prediction serving in the Runtime where physical stages and parameters are shared among pipelines with similar model plans.\n\non-line phase:\n\nphysical stages are parameterized dynamically with the proper values maintained in the ObjectStore. \nThe Scheduler is in charge of binding physical stages to shared execution units.\n\nCloudburst: Stateful Functions-as-a-ServiceToday’s popular FaaS platforms only work well for isolated, stateless functions. \n\nThe hallmark autoscaling feature of serverless platforms is enabled by an increasingly popular design principle: the disaggregation of storage and compute services.Unfortunately, today’s FaaS platforms take disaggregation to an extreme. \n\nWe are interested in exploring designs that preserve the autoscaling and operational benefits of current offerings(FaaS), while adding performant, cost-efficient, and consistent shared state and communication(Stateful).\nStateful Serverless via logical disaggregation with physical colocation(LDPC):\n\ndeploy resources to diffierent services in close physical proximity.\n\nThis paper presents a new Function-as-a-Service platform called Cloudburst. Cloudburst achieves this via a combination of an autoscaling key-value store (providing state sharing and overlay routing) and mutable caches co-located with function executors (providing data locality).\nToday’s Serverless Functions:Function Composition: AWS Lambda imposes a latency overhead of up to 20ms for a single functioninvocation.\nDirect Communication: point-to-point communication may seem tricky in a system with dynamic membership, distributed hashtables (DHTs) or lightweight key-value stores (KVSs) can provide a lower-latency solution.\nLow-Latency Access to Shared Mutable State: worse than shared memory, weak data consistency guarantees.\nStateful Serverless:distributed storage(KVS server) and local caching(KVS cache).\nCoordination-free consistency.\nProgramming InterfaceTo enable stateful functions, Cloudburst allows programmers to put and get Python objects via the Anna KVS API.\nFor repeated execution, Cloudburst allows users to register arbitrary compositions of functions as DAGs.\n\nArchitecture\nUser requests are received by a scheduler, which routes them to function executors. Each scheduler operates independently, and the system relies on a standard stateless cloud load balancer(AWS Elastic Load Balancer).\n Function executors run in individual processes that are packed into VMs along with a local cache per VM. The cache on each VM intermediates between the local executors and the remote KVS.\nAll Cloudburst components are run in individual Docker containers. Cloudburst uses Kubernetes [49] simply to start containers and redeploy them on failure.\nFunction Executors: Before each invocation, the executor retrieves and deserializes the requested function and transparently resolves all KVS reference function arguments in parallel.\nCaches: To ensure that frequently-used data is locally available, every function execution VM has a local cache, which executors contact via IPC.\nFunction Schedulers: prioritize data locality when scheduling both single functions and DAGs. picks the executor with the most data cached locally.\nMonitoring and Resource Management: For each DAG, If the incoming request rate is significantly higher than the request completion rate of the system, the monitoring engine will increase the resources allocated to that DAG function.\nFault Tolerance: If a machine fails while executing a function, the whole DAG is re-executed after a configurable timeout. \nOptimizing Prediction Serving on Low-Latency Serverless Dataflowprediction serving three key properties:\n\ncomputationally intensive\nlow latency requirements\ncompositional, meaning a single request passes through multiple stages.\n(for system) must operate in the presence of bursty and unpredictable workloads.\n\nAWS Sagemaker and Azure ML deploy individual models as separate microservices, However, this approach:\n\nno visibility into the structure\nhow the individual microservices relate to each other, which significantly complicates debugging and limits end-to-end performance optimization.\n\nPretzel:requires the developer to rewrite their individual models (i.e., pipeline stages) which is cumbersome and limits model development.\nIn this paper, (black-box) operators, which are typically models trained by users in their library of choice. A graph of familiar dataflow operators (e.g., map, filter, join) can be used to wrap black-box models.\nThey present Cloudflow, a dataflow system for prediction serving pipelines. Cloudflow is built on top of Cloudburst.\nArchitecture and API\nDataflow API:\nanyof passes exactly one of its input tables to the output.\nfuse is an internal operator that executes multiple other operators over a Table.\n\nCloudflow also has an extend method. extend takes in another valid flow as an argument and appends its DAG to the existing flow, creating a dataflow that chains the pair.\nOptimizing DataflowsAll the techniques described in this section are automatic optimizations; the user only needs to select which optimizations to enable.\nOperator Fusion: compiled into a single Cloudburst function. greedily fuse operators with same resource requirements.\nCompetitive Execution: reduce the tail latency, redundant parallel replicas of the operator in question and add an anyof to consume the results.\nOperator Autoscaling and Placement: Cloudburst natively autoscales function individually. Then we extended the Cloudburst API to allow functions to be annotated with different resource class labels.\nData Locality via Dynamic Dispatch: \n\nCloudflow fuses each lookup operator with the operator downstream from it.\nCloudburst to perform dynamic dispatch of the (fused) operator at a machine that has cached the column value.\n\nBatching: Cloudflow’s API provides a flag for the function arguments to map and filter to declare batch-awareness. Cloudburst dequeues multiple execution requests and executes the entire batch in a single.\nNotesFasS\n\nlow latency\ncost efficieny\nworkload burst from 0 to most\ncan do training?\n\n","dateCreated":"2020-09-02T07:31:18+08:00","dateModified":"2024-02-17T03:23:49+08:00","datePublished":"2020-09-02T07:31:18+08:00","description":"Paper summary for Model Serving","headline":"Model Serving","image":["https://1.bp.blogspot.com/-cLxpo2BA8oI/XZMQrDSXefI/AAAAAAAAnhs/7FS6r94KFNQFzVt_8Ihx1iyTltt7if_xgCLcBGAsYHQ/s1600/TensorFlow%2B2.0%2BLogo.png","https://www.eetasia.com/wp-content/uploads/sites/2/images/c806bc6b-a80c-4ed7-808e-3cc362811e28.jpg"],"mainEntityOfPage":{"@type":"WebPage","@id":"http://joddiy.cc/2020/09/02/Model-Serving/"},"publisher":{"@type":"Organization","name":"Joddiy Zhang","sameAs":["https://github.com/joddiy","https://scholar.google.com/citations?user=KH-xv38AAAAJ&hl=en&oi=sra","https://www.linkedin.com/in/joddiyzhang/"],"image":"14108933.jpeg","logo":{"@type":"ImageObject","url":"14108933.jpeg"}},"url":"http://joddiy.cc/2020/09/02/Model-Serving/","keywords":"Tools, Deep Learning","thumbnailUrl":"https://1.bp.blogspot.com/-cLxpo2BA8oI/XZMQrDSXefI/AAAAAAAAnhs/7FS6r94KFNQFzVt_8Ihx1iyTltt7if_xgCLcBGAsYHQ/s1600/TensorFlow%2B2.0%2BLogo.png"}</script>
    <meta name="description" content="Paper summary for Model Serving">
<meta property="og:type" content="blog">
<meta property="og:title" content="Model Serving">
<meta property="og:url" content="http://joddiy.cc/2020/09/02/Model-Serving/index.html">
<meta property="og:site_name" content="Jz Blog">
<meta property="og:description" content="Paper summary for Model Serving">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://joddiy.cc/2020/09/02/Model-Serving/1.png">
<meta property="og:image" content="http://joddiy.cc/2020/09/02/Model-Serving/2.png">
<meta property="og:image" content="http://joddiy.cc/2020/09/02/Model-Serving/3.png">
<meta property="og:image" content="http://joddiy.cc/2020/09/02/Model-Serving/4.png">
<meta property="og:image" content="http://joddiy.cc/2020/09/02/Model-Serving/5.png">
<meta property="og:image" content="http://joddiy.cc/2020/09/02/Model-Serving/6.png">
<meta property="article:published_time" content="2020-09-01T23:31:18.000Z">
<meta property="article:modified_time" content="2024-02-16T19:23:49.898Z">
<meta property="article:author" content="Joddiy Zhang">
<meta property="article:tag" content="Tools">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://joddiy.cc/2020/09/02/Model-Serving/1.png">
    
    
        
    
    
        <meta property="og:image" content="http://joddiy.cc/assets/images/14108933.jpeg"/>
    
    
        <meta property="og:image" content="https://1.bp.blogspot.com/-cLxpo2BA8oI/XZMQrDSXefI/AAAAAAAAnhs/7FS6r94KFNQFzVt_8Ihx1iyTltt7if_xgCLcBGAsYHQ/s1600/TensorFlow%2B2.0%2BLogo.png"/>
        <meta class="swiftype" name="image" data-type="enum" content="https://1.bp.blogspot.com/-cLxpo2BA8oI/XZMQrDSXefI/AAAAAAAAnhs/7FS6r94KFNQFzVt_8Ihx1iyTltt7if_xgCLcBGAsYHQ/s1600/TensorFlow%2B2.0%2BLogo.png"/>
    
    
        <meta property="og:image" content="https://www.eetasia.com/wp-content/uploads/sites/2/images/c806bc6b-a80c-4ed7-808e-3cc362811e28.jpg"/>
        <meta class="swiftype" name="image" data-type="enum" content="https://www.eetasia.com/wp-content/uploads/sites/2/images/c806bc6b-a80c-4ed7-808e-3cc362811e28.jpg"/>
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-x8blglznjjnb9pnnwui5zw4h43ysufmsh1b0omicawm4vhqcutzqavokgpne.min.css">

    <!--STYLES END-->
    

    

    
        
    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="4">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            Jz Blog
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Open the link: /#about"
            >
        
        
            <img class="header-picture" src="/assets/images/14108933.jpeg" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="4">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="Read more about the author"
                >
                    <img class="sidebar-profile-picture" src="/assets/images/14108933.jpeg" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">Joddiy Zhang</h4>
                
                    <h5 class="sidebar-profile-bio"><p><a href="mailto:&#106;&#x6f;&#x64;&#x64;&#105;&#x79;&#122;&#104;&#x61;&#110;&#x67;&#64;&#x67;&#x6d;&#97;&#105;&#x6c;&#46;&#x63;&#x6f;&#x6d;">&#106;&#x6f;&#x64;&#x64;&#105;&#x79;&#122;&#104;&#x61;&#110;&#x67;&#64;&#x67;&#x6d;&#97;&#105;&#x6c;&#46;&#x63;&#x6f;&#x6d;</a></p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="Home"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="Categories"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Categories</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="Tags"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="Archives"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Archives</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="About"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/joddiy"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://scholar.google.com/citations?user=KH-xv38AAAAJ&hl=en&oi=sra"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Google Scholar"
                        >
                        <i class="sidebar-button-icon fab fa-google" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Google Scholar</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://www.linkedin.com/in/joddiyzhang/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="LinkedIn"
                        >
                        <i class="sidebar-button-icon fab fa-linkedin" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">LinkedIn</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
        <div class="post-header-cover
                    text-center
                    post-header-cover--partial"
             style="background-image:url('https://www.eetasia.com/wp-content/uploads/sites/2/images/c806bc6b-a80c-4ed7-808e-3cc362811e28.jpg');"
             data-behavior="4">
            
                <div class="post-header main-content-wrap text-center">
    
        <h1 class="post-title">
            Model Serving
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2020-09-02T07:31:18+08:00">
	
		    Sep 02, 2020
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Study-Notes/">Study Notes</a>


    
</div>

    
</div>

            
        </div>

            <div id="main" data-behavior="4"
                 class="hasCover
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <h1 id="From-the-Edge-to-the-Cloud-Model-Serving-in-ML-NET"><a href="#From-the-Edge-to-the-Cloud-Model-Serving-in-ML-NET" class="headerlink" title="From the Edge to the Cloud: Model Serving in ML.NET"></a>From the Edge to the Cloud: Model Serving in ML.NET</h1><p>In this paper, they:</p>
<ul>
<li>give an overview of current state of the art practices for surfacing ML pipelines predictions into applications</li>
<li>highlight the limitations of using containers to operationalize models for application consumption.</li>
</ul>
<h2 id="Model-Serving-An-Overview"><a href="#Model-Serving-An-Overview" class="headerlink" title="Model Serving: An Overview"></a>Model Serving: An Overview</h2><p><img src="/2020/09/02/Model-Serving/1.png"></p>
<h2 id="Deploying-Models-into-Containers"><a href="#Deploying-Models-into-Containers" class="headerlink" title="Deploying Models into Containers"></a>Deploying Models into Containers</h2><p>The first option, depicted in Figure 2(a) is to ship models into containers (e.g., Docker [4]) wired with proper Remote Procedure Calls(RPCs) to a Web Server. With this approach, predictions have to go through the network and be rendered on the cloud: low latency or edge scenarios are therefore out of scope.</p>
<p>Pros:</p>
<ul>
<li>decoupling models from serving system development.</li>
<li>eases the implementation of mechanisms and policies for fault tolerance and scalability. </li>
<li>hardware acceleration can be exploited when available.</li>
</ul>
<p>Cons:</p>
<ul>
<li>each container comes with its own runtime and set of processes, thus introducing memory overheads that can possibly be higher than the actual model size.</li>
<li>the RPC layer and REST API introduce network communication costs.</li>
<li>only a restricted set of optimizations are available, no knowledge of the internals of the pipelines.</li>
</ul>
<h2 id="Importing-Models-Directly-into-Applications"><a href="#Importing-Models-Directly-into-Applications" class="headerlink" title="Importing Models Directly into Applications"></a>Importing Models Directly into Applications</h2><p>The second option (Figure 2(b) is to integrate the model logic directly into the application(ML.NET: the model is a dynamic library the application can link). This approach is suitable for the cloud as well as for edge devices and it unlocks low latency scenarios.</p>
<p>Pros:</p>
<ul>
<li>removes the overhead of managing containers and implementing RPC functionalities to communicate with the Serving System.</li>
</ul>
<p>Cons:</p>
<ul>
<li>sub-optimal from a performance perspective, DAGs with high chance of overlapping structure and similar parameters, but these similarities cannot be recognized nor exploited using a black-box approach.</li>
</ul>
<h2 id="White-Box-Model-Serving"><a href="#White-Box-Model-Serving" class="headerlink" title="White Box Model Serving"></a>White Box Model Serving</h2><p>Models are registered to a Runtime that considers them not as mere executable code but as DAGs of operators.</p>
<p>Pros:</p>
<ul>
<li>apply optimizations over the models such as operator reordering to improve latency or operator and sub-graph sharing to improve memory consumption and computation reuse.</li>
</ul>
<p>End-to-end Optimizations:</p>
<ul>
<li>avoid memory allocation on the data path</li>
<li>avoid creating separate routines per operator when possible</li>
<li>avoid reflection and JIT compilation at prediction time</li>
</ul>
<p>Multi-model Optimizations:</p>
<ul>
<li>shareable components have to be uniquely stored in memory and reused as much as possible to achieve optimal memory usage</li>
</ul>
<h2 id="PRETZEL"><a href="#PRETZEL" class="headerlink" title="PRETZEL"></a>PRETZEL</h2><p>PRETZEL views models as database queries and employs database techniques to optimize DAGs and to improve end-to-end performance.</p>
<p><img src="/2020/09/02/Model-Serving/2.png"></p>
<p>off-line phase:</p>
<ul>
<li>pre-trained ML.NET pipelines are translated into Flour transformations. </li>
<li>Oven optimizer re-arranges and fuses transformations into model plans composed of parameterized logical units called stages. </li>
<li>Each logical stage is then Ahead-Of-Time(AOT)-compiled into physical computation units. </li>
<li>Logical and physical stages together with model parameters and training statistics form a model plan. </li>
<li>Model plans are registered for prediction serving in the Runtime where physical stages and parameters are shared among pipelines with similar model plans.</li>
</ul>
<p>on-line phase:</p>
<ul>
<li>physical stages are parameterized dynamically with the proper values maintained in the ObjectStore. </li>
<li>The Scheduler is in charge of binding physical stages to shared execution units.</li>
</ul>
<h1 id="Cloudburst-Stateful-Functions-as-a-Service"><a href="#Cloudburst-Stateful-Functions-as-a-Service" class="headerlink" title="Cloudburst: Stateful Functions-as-a-Service"></a>Cloudburst: Stateful Functions-as-a-Service</h1><p>Today’s popular FaaS platforms only work well for isolated, stateless functions. </p>
<blockquote>
<p>The hallmark autoscaling feature of serverless platforms is enabled by an increasingly popular design principle: the disaggregation of storage and compute services.<br>Unfortunately, today’s FaaS platforms take disaggregation to an extreme. </p>
</blockquote>
<p>We are interested in exploring designs that preserve the autoscaling and operational benefits of current offerings(FaaS), while adding performant, cost-efficient, and consistent shared state and communication(Stateful).</p>
<p>Stateful Serverless via logical disaggregation with physical colocation(LDPC):</p>
<ul>
<li>deploy resources to diffierent services in close physical proximity.</li>
</ul>
<p>This paper presents a new Function-as-a-Service platform called Cloudburst. Cloudburst achieves this via a combination of an autoscaling key-value store (providing state sharing and overlay routing) and mutable caches co-located with function executors (providing data locality).</p>
<h2 id="Today’s-Serverless-Functions"><a href="#Today’s-Serverless-Functions" class="headerlink" title="Today’s Serverless Functions:"></a>Today’s Serverless Functions:</h2><p>Function Composition: AWS Lambda imposes a latency overhead of up to 20ms for a single function<br>invocation.</p>
<p>Direct Communication: point-to-point communication may seem tricky in a system with dynamic membership, distributed hashtables (DHTs) or lightweight key-value stores (KVSs) can provide a lower-latency solution.</p>
<p>Low-Latency Access to Shared Mutable State: worse than shared memory, weak data consistency guarantees.</p>
<h2 id="Stateful-Serverless"><a href="#Stateful-Serverless" class="headerlink" title="Stateful Serverless:"></a>Stateful Serverless:</h2><p>distributed storage(KVS server) and local caching(KVS cache).</p>
<p>Coordination-free consistency.</p>
<h2 id="Programming-Interface"><a href="#Programming-Interface" class="headerlink" title="Programming Interface"></a>Programming Interface</h2><p>To enable stateful functions, Cloudburst allows programmers to put and get Python objects via the Anna KVS API.</p>
<p>For repeated execution, Cloudburst allows users to register arbitrary compositions of functions as DAGs.</p>
<p><img src="/2020/09/02/Model-Serving/3.png"></p>
<h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p><img src="/2020/09/02/Model-Serving/4.png"></p>
<p>User requests are received by a scheduler, which routes them to function executors. Each scheduler operates independently, and the system relies on a standard stateless cloud load balancer(AWS Elastic Load Balancer).</p>
<p> Function executors run in individual processes that are packed into VMs along with a local cache per VM. The cache on each VM intermediates between the local executors and the remote KVS.</p>
<p>All Cloudburst components are run in individual Docker containers. Cloudburst uses Kubernetes [49] simply to start containers and redeploy them on failure.</p>
<p><strong>Function Executors:</strong> Before each invocation, the executor retrieves and deserializes the requested function and transparently resolves all KVS reference function arguments in parallel.</p>
<p><strong>Caches:</strong> To ensure that frequently-used data is locally available, every function execution VM has a local cache, which executors contact via IPC.</p>
<p><strong>Function Schedulers</strong>: prioritize data locality when scheduling both single functions and DAGs. picks the executor with the most data cached locally.</p>
<p><strong>Monitoring and Resource Management</strong>: For each DAG, If the incoming request rate is significantly higher than the request completion rate of the system, the monitoring engine will increase the resources allocated to that DAG function.</p>
<p><strong>Fault Tolerance:</strong> If a machine fails while executing a function, the whole DAG is re-executed after a configurable timeout. </p>
<h1 id="Optimizing-Prediction-Serving-on-Low-Latency-Serverless-Dataflow"><a href="#Optimizing-Prediction-Serving-on-Low-Latency-Serverless-Dataflow" class="headerlink" title="Optimizing Prediction Serving on Low-Latency Serverless Dataflow"></a>Optimizing Prediction Serving on Low-Latency Serverless Dataflow</h1><p>prediction serving three key properties:</p>
<ul>
<li>computationally intensive</li>
<li>low latency requirements</li>
<li>compositional, meaning a single request passes through multiple stages.</li>
<li>(for system) must operate in the presence of bursty and unpredictable workloads.</li>
</ul>
<p>AWS Sagemaker and Azure ML deploy individual models as separate microservices, However, this approach:</p>
<ul>
<li>no visibility into the structure</li>
<li>how the individual microservices relate to each other, which significantly complicates debugging and limits end-to-end performance optimization.</li>
</ul>
<p>Pretzel:<br>requires the developer to rewrite their individual models (i.e., pipeline stages) which is cumbersome and limits model development.</p>
<p>In this paper, (black-box) operators, which are typically models trained by users in their library of choice. A graph of familiar dataflow operators (e.g., map, filter, join) can be used to wrap black-box models.</p>
<p>They present Cloudflow, a dataflow system for prediction serving pipelines. Cloudflow is built on top of Cloudburst.</p>
<h2 id="Architecture-and-API"><a href="#Architecture-and-API" class="headerlink" title="Architecture and API"></a>Architecture and API</h2><p><img src="/2020/09/02/Model-Serving/5.png"></p>
<p>Dataflow API:</p>
<p>anyof passes exactly one of its input tables to the output.</p>
<p>fuse is an internal operator that executes multiple other operators over a Table.</p>
<p><img src="/2020/09/02/Model-Serving/6.png"></p>
<p>Cloudflow also has an extend method. extend takes in another valid flow as an argument and appends its DAG to the existing flow, creating a dataflow that chains the pair.</p>
<h2 id="Optimizing-Dataflows"><a href="#Optimizing-Dataflows" class="headerlink" title="Optimizing Dataflows"></a>Optimizing Dataflows</h2><p>All the techniques described in this section are automatic optimizations; the user only needs to select which optimizations to enable.</p>
<p><strong>Operator Fusion:</strong> compiled into a single Cloudburst function. greedily fuse operators with same resource requirements.</p>
<p><strong>Competitive Execution:</strong> reduce the tail latency, redundant parallel replicas of the operator in question and add an anyof to consume the results.</p>
<p><strong>Operator Autoscaling and Placement:</strong> Cloudburst natively autoscales function individually. Then we extended the Cloudburst API to allow functions to be annotated with different resource class labels.</p>
<p><strong>Data Locality via Dynamic Dispatch:</strong> </p>
<ul>
<li>Cloudflow fuses each lookup operator with the operator downstream from it.</li>
<li>Cloudburst to perform dynamic dispatch of the (fused) operator at a machine that has cached the column value.</li>
</ul>
<p><strong>Batching:</strong> Cloudflow’s API provides a flag for the function arguments to map and filter to declare batch-awareness. Cloudburst dequeues multiple execution requests and executes the entire batch in a single.</p>
<h1 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h1><p>FasS</p>
<ul>
<li>low latency</li>
<li>cost efficieny</li>
<li>workload burst from 0 to most</li>
<li>can do training?</li>
</ul>

            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">TAGGED IN</span><br/>
                
    <a class="tag tag--primary tag--small t-none-link" href="/tags/Deep-Learning/" rel="tag">Deep Learning</a> <a class="tag tag--primary tag--small t-none-link" href="/tags/Tools/" rel="tag">Tools</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2020/09/09/Serverless-Computing/"
                    data-tooltip="Serverless Computing"
                    aria-label="PREVIOUS: Serverless Computing"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2020/08/18/DNN-Computation-Optimization/"
                    data-tooltip="DNN Inference Accelerator"
                    aria-label="NEXT: DNN Inference Accelerator"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=http://joddiy.cc/2020/09/02/Model-Serving/"
                    title="Share on Facebook"
                    aria-label="Share on Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=http://joddiy.cc/2020/09/02/Model-Serving/"
                    title="Share on Twitter"
                    aria-label="Share on Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://plus.google.com/share?url=http://joddiy.cc/2020/09/02/Model-Serving/"
                    title="Share on Google+"
                    aria-label="Share on Google+"
                >
                    <i class="fab fa-google-plus" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2024 Joddiy Zhang. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2020/09/09/Serverless-Computing/"
                    data-tooltip="Serverless Computing"
                    aria-label="PREVIOUS: Serverless Computing"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2020/08/18/DNN-Computation-Optimization/"
                    data-tooltip="DNN Inference Accelerator"
                    aria-label="NEXT: DNN Inference Accelerator"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=http://joddiy.cc/2020/09/02/Model-Serving/"
                    title="Share on Facebook"
                    aria-label="Share on Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=http://joddiy.cc/2020/09/02/Model-Serving/"
                    title="Share on Twitter"
                    aria-label="Share on Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://plus.google.com/share?url=http://joddiy.cc/2020/09/02/Model-Serving/"
                    title="Share on Google+"
                    aria-label="Share on Google+"
                >
                    <i class="fab fa-google-plus" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="4">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=http://joddiy.cc/2020/09/02/Model-Serving/"
                        aria-label="Share on Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>Share on Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=http://joddiy.cc/2020/09/02/Model-Serving/"
                        aria-label="Share on Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>Share on Twitter</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://plus.google.com/share?url=http://joddiy.cc/2020/09/02/Model-Serving/"
                        aria-label="Share on Google+"
                    >
                        <i class="fab fa-google-plus" aria-hidden="true"></i><span>Share on Google+</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/14108933.jpeg" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">Joddiy Zhang</h4>
        
            <div id="about-card-bio"><p><a href="mailto:&#106;&#111;&#100;&#100;&#105;&#121;&#x7a;&#104;&#97;&#110;&#103;&#x40;&#103;&#x6d;&#x61;&#105;&#108;&#46;&#99;&#111;&#x6d;">&#106;&#111;&#100;&#100;&#105;&#121;&#x7a;&#104;&#97;&#110;&#103;&#x40;&#103;&#x6d;&#x61;&#105;&#108;&#46;&#99;&#111;&#x6d;</a></p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>Machine Learning Engineer</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Singapore
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-sqrh47zm5nkjgifq4rx38uvns4r2rarrrvwuhjxiztyrddruca5ukl7nw6br.min.js"></script>

<!--SCRIPTS END-->


    




    </body>
</html>
